{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnettd/llm-project/blob/reorg/1-classify-with-scikit-learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KIIomXgAl3t"
      },
      "source": [
        "# Sentiment Analysis of Movie Reviews using `TfidfVectorizer` and Classifiers from scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67ZjtS_aAl3w"
      },
      "source": [
        "In this notebook, I perform sentiment analysis of movie reviews using classes available in `scikit-learn`.\n",
        "\n",
        "The dataset consists of 50k highly polarized (*clearly* favourable or unfavourable) movie reviews from IMBD. The set is partitioned into a labelled train set of 25k reviews and a labelled test set of 25k reviews. The reviews are preprocessed by lower-casing, removing HTML tags, and removing punctutation. The reviews are then tokenized, removing English stop words, and stemmed. Corpus vectorization is implemented using `TfidfVectorizer`. Multiple classification models from `scikit-learn` are trained and tested on the results. The best performing model is pickled for later deployment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/harnettd/llm-project.git\n",
        "%cd llm-project\n",
        "!git checkout reorg"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TaiDwwBKLz8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkrHBlbYAl3x"
      },
      "source": [
        "## Installs and Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "v_qLLHovA2MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqlKD6gqAl3x"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "from scipy.stats import loguniform, uniform\n",
        "\n",
        "from nltk import PorterStemmer\n",
        "\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from app.cleaner.preprocessor import Preprocessor\n",
        "from app.cleaner.tokenizer import Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtGIM-fHAl3z"
      },
      "source": [
        "## Load the IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFKINTFAAl3z"
      },
      "outputs": [],
      "source": [
        "ds = load_dataset('imdb')\n",
        "train, test = pd.DataFrame(ds['train']), pd.DataFrame(ds['test'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZC1PiMoAl30"
      },
      "source": [
        "In the following DataFrame samples, a label of 0 corresponds to a negative review (*i.e.,* thumbs-down) whereas a label of 1 corresponds to a positive review (*i.e.,* thumbs-up)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyHpQb8PAl30"
      },
      "outputs": [],
      "source": [
        "train.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CAvFD9NAl32"
      },
      "outputs": [],
      "source": [
        "test.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRIZs_4BAl33"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpY10rt5Al33"
      },
      "outputs": [],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I plot the distribution of movie review labels in the train set."
      ],
      "metadata": {
        "id": "Xiru_f-c7EUu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWJ-GVkxAl33"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "train.groupby('label').count().plot(kind='bar', alpha=0.75, ax=ax)\n",
        "ax.set_ylabel('count')\n",
        "ax.set_title('Distribution of movie review labels')\n",
        "ax.legend().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28Xd_9kzAl33"
      },
      "source": [
        "From the above bar graph, the train set appears to be balanced. To confirm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owpeKomDAl34"
      },
      "outputs": [],
      "source": [
        "train['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGY5KMnTAl34"
      },
      "source": [
        "It is instructive to read a handful of reviews to better understand what is meant by \"highly polarized.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxSsAw5RAl34"
      },
      "outputs": [],
      "source": [
        "thumbs_ups = train[train['label'] == 1]\n",
        "thumbs_downs = train[train['label'] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo1V8uqFAl34"
      },
      "outputs": [],
      "source": [
        "thumbs_up_samples = thumbs_ups['text'].sample(3).to_list()\n",
        "print('\\n\\n'.join(thumbs_up_samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivqXrzAJAl34"
      },
      "outputs": [],
      "source": [
        "thumbs_down_samples = thumbs_downs['text'].sample(3).to_list()\n",
        "print('\\n\\n'.join(thumbs_down_samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, it is pretty clear from reading a particular review whether it is a thumbs-up or thumbs-down."
      ],
      "metadata": {
        "id": "nq5P_Iu1QmaY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eG6a3t6Al35"
      },
      "source": [
        "## Preprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bk2TBv9Al35"
      },
      "source": [
        "The preprocessor transforms movie reviews by lower-casing, removing HTML tags, and removing punctuation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = Preprocessor()"
      ],
      "metadata": {
        "id": "6fpUHAnuQhhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6OwlrxwAl36"
      },
      "source": [
        "To see the preprocessor in action, pick a random movie review:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKlkpY7qAl36"
      },
      "outputs": [],
      "source": [
        "doc = train['text'].sample()\n",
        "doc_preprocessed = preprocessor.transform(doc)\n",
        "\n",
        "print(doc.to_list()[0])\n",
        "print()\n",
        "print(doc_preprocessed[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8ImtNQfAl36"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWYN34CRAl36"
      },
      "source": [
        "The tokenizer removes English stop words and stems the corpus."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(PorterStemmer(), ENGLISH_STOP_WORDS)"
      ],
      "metadata": {
        "id": "fhCrqrDSB1JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vcEsH_eAl37"
      },
      "source": [
        "To see the tokenizer in action, transform the previously preprocessed movie review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCbxTmNTAl37"
      },
      "outputs": [],
      "source": [
        "doc_tokenized = tokenizer.transform(doc_preprocessed)\n",
        "\n",
        "print(doc_preprocessed[0])\n",
        "print()\n",
        "print(doc_tokenized[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorizer"
      ],
      "metadata": {
        "id": "UYeNXdMWCQtc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use the `TfidfVectorizer` to map documents to vectors."
      ],
      "metadata": {
        "id": "kJyVHilfCXk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(\n",
        "    max_df = 0.95,\n",
        "    min_df = 2,\n",
        "    max_features = 10_000,\n",
        "    strip_accents='unicode'\n",
        ")\n",
        "\n",
        "cleaner = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('tokenizer', tokenizer),\n",
        "    ('vectorizer', vectorizer)\n",
        "])"
      ],
      "metadata": {
        "id": "KKSbw_iiRoRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YAgpYi-Al37"
      },
      "source": [
        "## Classifers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I train and test logistic regression, random forest, and support vector machine classifiers on the IMDB movie reviews. I score the models using F1-score because the train set is balanced and the consequences of misclassifying a positive review are the same as misclassifying a negative review."
      ],
      "metadata": {
        "id": "kTpL6bQ28FgG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQEm6eAbAl37"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test =\\\n",
        "    train['text'], test['text'], train['label'], test['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uGBmXsNAl37"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWfWV2_sAl37"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    solver='saga',\n",
        "    max_iter=500\n",
        ")\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('cleaner', cleaner),\n",
        "    ('classifier', lr)\n",
        "])\n",
        "\n",
        "param_distributions = {\n",
        "    'classifier__C': loguniform(1e-2, 1e2)\n",
        "}\n",
        "\n",
        "search_lr = RandomizedSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=1,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=1,\n",
        "    refit=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOa1gKCmAl38"
      },
      "outputs": [],
      "source": [
        "search_lr.fit(X_train, y_train);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_score_lr = search_lr.score(X_test, y_test)\n",
        "\n",
        "print(f'Best parameters: {search_lr.best_params_}')\n",
        "print(f'Test F1-score: {test_score_lr}')"
      ],
      "metadata": {
        "id": "s2vSpT-GYX6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = search_lr.best_estimator_\n",
        "best_score = test_score_lr"
      ],
      "metadata": {
        "id": "-deFy3WYMqAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "lKqLIcDJNnyK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRP4PVpwAl38"
      },
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier()\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('cleaner', cleaner),\n",
        "    ('classifier', rfc)\n",
        "])\n",
        "\n",
        "param_distributions = {\n",
        "    'classifier__n_estimators': [10, 30, 100, 300, 1000],\n",
        "    'classifier__max_depth': list(range(10, 101)),\n",
        "    'classifier__min_samples_split': list(range(2, 11)),\n",
        "    'classifier__min_samples_leaf': list(range(1, 11))\n",
        "}\n",
        "\n",
        "search_rfc = RandomizedSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=1,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=1,\n",
        "    refit=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_rfc.fit(X_train, y_train);"
      ],
      "metadata": {
        "id": "VpVfqqUrOVKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score_rfc = search_rfc.score(X_test, y_test)\n",
        "\n",
        "print(f'Best parameters: {search_rfc.best_params_}')\n",
        "print(f'Test F1-score: {test_score_rfc}')"
      ],
      "metadata": {
        "id": "vtZIsatbZBi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if test_score_rfc > best_score:\n",
        "    best_model = search_rfc.best_estimator_\n",
        "    best_score = test_score_rfc"
      ],
      "metadata": {
        "id": "_PI7XehrNS_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine"
      ],
      "metadata": {
        "id": "_4dTJFlzdR5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svc = LinearSVC(penalty='l2', max_iter=500)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('cleaner', cleaner),\n",
        "    ('classifier', svc)\n",
        "])\n",
        "\n",
        "param_distributions = {\n",
        "    'classifier__C': loguniform(1e-2, 1e2)\n",
        "}\n",
        "\n",
        "search_svc = RandomizedSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=1,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    n_jobs=1,\n",
        "    refit=True\n",
        ")"
      ],
      "metadata": {
        "id": "OzZlXEXIdXPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_svc.fit(X_train, y_train);"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-ol8BGeDeQ6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score_svc = search_svc.score(X_test, y_test)\n",
        "\n",
        "print(f'Best model: {search_svc.best_params_}')\n",
        "print(f'Test F1-score: {test_score_svc}')"
      ],
      "metadata": {
        "id": "DKeHEuvyeYFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if test_score_svc > best_score:\n",
        "    best_model = search_svc.best_estimator_\n",
        "    best_score = test_score_svc"
      ],
      "metadata": {
        "id": "I7XR2vcANmlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "E4nMSB0TUPEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test F1-scores:')\n",
        "print(f'    Logistic regression: {test_score_lr}')\n",
        "print(f'    Random forest: {test_score_rfc}')\n",
        "print(f'    Support vector machine: {test_score_svc}')"
      ],
      "metadata": {
        "id": "OIYkP5g2UTM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I pickle the best-performing model so that it can be deployed later."
      ],
      "metadata": {
        "id": "w0xrCOYo9eJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = 'app/model'\n",
        "with open(f'{model_dir}/best_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_model, file)"
      ],
      "metadata": {
        "id": "oZT0s9JA6DZB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}